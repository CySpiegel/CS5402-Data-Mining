subSystemP5 = hw8_data[, c("is_attack","AIT501","AIT502","AIT503","AIT504","FIT501","FIT502","FIT503","FIT504","PIT501","PIT502","PIT503")]
subSystemP6 = hw8_data[, c("is_attack","P601","FIT601")]
options(mc.cores = 7)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
View(subSystemP6)
View(subSystemP5)
View(subSystemP6)
trainingSetSubSysP6 = sample(seq_len(nrow(subSystemP6)), size = floor(0.66*nrow(subSystemP6)))
xTrainSubSusP6 = subSystemP6[trainingSetSubSysP6,2:3]
yTrainSubSysP6 = as.numeric(subSystemP6[trainingSetSubSysP6, 1])
xTestSubSysP6 = subSystemP6[-trainingSetSubSysP6,2:3]
yTestSubSysP6 = as.numeric(subSystemP6[-trainingSetSubSysP6, 1])
View(xTestSubSysP6)
View(xTrainSubSusP6)
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(xgboost)
# SubSystemP6 Training and test sets.
trainingSetSubSysP6 = sample(seq_len(nrow(subSystemP6)), size = floor(0.66*nrow(subSystemP6)))
xTrainSubSusP6 = subSystemP6[trainingSetSubSysP6,2:3]
yTrainSubSysP6 = as.numeric(subSystemP6[trainingSetSubSysP6, 1])
xTestSubSysP6 = subSystemP6[-trainingSetSubSysP6,2:3]
yTestSubSysP6 = as.numeric(subSystemP6[-trainingSetSubSysP6, 1])
# SybSystemP6 modeling
modelSubSysP6 = SuperLearner(Y = yTrainSubSysP6, X = xTrainSubSusP6, family = binomial(), SL.library = algorithmList)
predictionSubSysP6 = predict.SuperLearner(modelSubSysP6, newdata = xTestSubSysP6)
predictedResultSubSysP6 = as.numeric(ifelse(predictionSubSysP6$pred>=0.5,1,0))
confMatrixSubSysP6 = confusionMatrix(as.factor(yTestSubSysP6), as.factor(predictedResultSubSysP6))
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
# SybSystemP6 modeling
modelSubSysP6 = SuperLearner(Y = yTrainSubSysP6, X = xTrainSubSusP6, family = binomial(), SL.library = algorithmList)
predictionSubSysP6 = predict.SuperLearner(modelSubSysP6, newdata = xTestSubSysP6)
predictedResultSubSysP6 = as.numeric(ifelse(predictionSubSysP6$pred>=0.5,1,0))
confMatrixSubSysP6 = confusionMatrix(as.factor(yTestSubSysP6), as.factor(predictedResultSubSysP6))
# SybSystemP6 modeling
modelSubSysP6 = SuperLearner(Y = yTrainSubSysP6, X = xTrainSubSusP6, family = binomial(), SL.library = algorithmList)
predictionSubSysP6 = predict.SuperLearner(modelSubSysP6, newdata = xTestSubSysP6)
predictedResultSubSysP6 = as.numeric(ifelse(predictionSubSysP6$pred>=0.5,1,0))
confMatrixSubSysP6 = confusionMatrix(as.factor(yTestSubSysP6), as.factor(predictedResultSubSysP6))
algorithmList = list("SL.mean","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
# SybSystemP6 modeling
modelSubSysP6 = SuperLearner(Y = yTrainSubSysP6, X = xTrainSubSusP6, family = binomial(), SL.library = algorithmList)
predictionSubSysP6 = predict.SuperLearner(modelSubSysP6, newdata = xTestSubSysP6)
predictedResultSubSysP6 = as.numeric(ifelse(predictionSubSysP6$pred>=0.5,1,0))
confMatrixSubSysP6 = confusionMatrix(as.factor(yTestSubSysP6), as.factor(predictedResultSubSysP6))
# SubSystemP6 Training and test sets.
trainingSetSubSysP6 = sample(seq_len(nrow(subSystemP6)), size = floor(0.66*nrow(subSystemP6)))
xTrainSubSusP6 = subSystemP6[trainingSetSubSysP6,2:8]
yTrainSubSysP6 = as.numeric(subSystemP6[trainingSetSubSysP6, 1])
xTestSubSysP6 = subSystemP6[-trainingSetSubSysP6,2:8]
yTestSubSysP6 = as.numeric(subSystemP6[-trainingSetSubSysP6, 1])
# SubsystemP1 modeling
modelSubSysP6 = SuperLearner(Y = yTrainSubSysP6, X = xTrainSubSusP6, family = binomial(), SL.library = algorithmList)
predictionSubSysP1 = predict.SuperLearner(modelSubSysP6, newdata = xTestSubSysP6)
predictedResultSubSysP6 = as.numeric(ifelse(predictionSubSysP6$pred>=0.5,1,0))
confMatrixSubSysP6 = confusionMatrix(as.factor(yTestSubSysP6), as.factor(predictedResultSubSysP6))
predictedResultSubSysP6
# SubSystemP1 CrossFold Validation for calculating Area Under Curve
system.time({
cv_slSubSysP6 = CV.SuperLearner(Y = yTrainSubSysP6, X = xTrainSubSusP6, family = binomial(),
# For a real analysis we would use V = 10.
V = 10,
parallel = "multicore",
method = "method.AUC",
SL.library = algorithmList)
})
trainingSetSubSysP6 = sample(seq_len(nrow(subSystemP6)), size = floor(0.66*nrow(subSystemP6)))
xTrainSubSusP6 = subSystemP6[trainingSetSubSysP6,2:3]
yTrainSubSysP6 = as.numeric(subSystemP6[trainingSetSubSysP6, 1])
xTestSubSysP6 = subSystemP6[-trainingSetSubSysP6,2:3]
yTestSubSysP6 = as.numeric(subSystemP6[-trainingSetSubSysP6, 1])
modelSubSysP6 = SuperLearner(Y = yTrainSubSysP6, X = xTrainSubSusP6, family = binomial(), SL.library = algorithmList)
predictionSubSysP1 = predict.SuperLearner(modelSubSysP6, newdata = xTestSubSysP6)
predictedResultSubSysP6 = as.numeric(ifelse(predictionSubSysP6$pred>=0.5,1,0))
confMatrixSubSysP6 = confusionMatrix(as.factor(yTestSubSysP6), as.factor(predictedResultSubSysP6))
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(xgboost)
subSystemP1 = hw8_data[, c("is_attack","P101","MV101","FIT101","LIT101")]
subSystemP2 = hw8_data[, c("is_attack","P203","P205","MV201","AIT201","AIT202","AIT203","FIT201")]
subSystemP3 = hw8_data[, c("is_attack","P301","MV301","MV302","MV304","MV303","DPIT301","FIT301","LIT301")]
subSystemP4 = hw8_data[, c("is_attack","P401","UV401","AIT402","FIT401","LIT401")]
subSystemP5 = hw8_data[, c("is_attack","AIT501","AIT502","AIT503","AIT504","FIT501","FIT502","FIT503","FIT504","PIT501","PIT502","PIT503")]
subSystemP6 = hw8_data[, c("is_attack","P601","FIT601")]
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
options(mc.cores = 7)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# SubSystemP1 Training and test sets.
trainingSetSubSysP1 = sample(seq_len(nrow(subSystemP1)), size = floor(0.66*nrow(subSystemP1)))
xTrainSubSusP1 = subSystemP1[trainingSetSubSysP1,2:5]
yTrainSubSysP1 = as.numeric(subSystemP1[trainingSetSubSysP1, 1])
xTestSubSysP1 = subSystemP1[-trainingSetSubSysP1,2:5]
yTestSubSysP1 = as.numeric(subSystemP1[-trainingSetSubSysP1, 1])
# SubSystemP2 Training and test sets.
trainingSetSubSysP2 = sample(seq_len(nrow(subSystemP2)), size = floor(0.66*nrow(subSystemP2)))
xTrainSubSusP2 = subSystemP2[trainingSetSubSysP2,2:8]
yTrainSubSysP2 = as.numeric(subSystemP2[trainingSetSubSysP2, 1])
xTestSubSysP2 = subSystemP2[-trainingSetSubSysP2,2:8]
yTestSubSysP2 = as.numeric(subSystemP2[-trainingSetSubSysP2, 1])
# SubSystemP3 Training and test sets.
trainingSetSubSysP3 = sample(seq_len(nrow(subSystemP3)), size = floor(0.66*nrow(subSystemP3)))
xTrainSubSusP3 = subSystemP3[trainingSetSubSysP3,2:9]
yTrainSubSysP3 = as.numeric(subSystemP3[trainingSetSubSysP3, 1])
xTestSubSysP3 = subSystemP3[-trainingSetSubSysP3,2:9]
yTestSubSysP3 = as.numeric(subSystemP3[-trainingSetSubSysP3, 1])
# SubSystemP4 Training and test sets.
trainingSetSubSysP4 = sample(seq_len(nrow(subSystemP4)), size = floor(0.66*nrow(subSystemP4)))
xTrainSubSusP4 = subSystemP4[trainingSetSubSysP4,2:6]
yTrainSubSysP4 = as.numeric(subSystemP4[trainingSetSubSysP4, 1])
xTestSubSysP4 = subSystemP4[-trainingSetSubSysP4,2:6]
yTestSubSysP4 = as.numeric(subSystemP4[-trainingSetSubSysP4, 1])
# SubSystemP5 Training and test sets.
trainingSetSubSysP5 = sample(seq_len(nrow(subSystemP5)), size = floor(0.66*nrow(subSystemP5)))
xTrainSubSusP5 = subSystemP5[trainingSetSubSysP5,2:12]
yTrainSubSysP5 = as.numeric(subSystemP5[trainingSetSubSysP5, 1])
xTestSubSysP5 = subSystemP5[-trainingSetSubSysP5,2:12]
yTestSubSysP5 = as.numeric(subSystemP5[-trainingSetSubSysP5, 1])
# SubSystemP6 Training and test sets.
trainingSetSubSysP6 = sample(seq_len(nrow(subSystemP6)), size = floor(0.66*nrow(subSystemP6)))
xTrainSubSusP6 = subSystemP6[trainingSetSubSysP6,2:3]
yTrainSubSysP6 = as.numeric(subSystemP6[trainingSetSubSysP6, 1])
xTestSubSysP6 = subSystemP6[-trainingSetSubSysP6,2:3]
yTestSubSysP6 = as.numeric(subSystemP6[-trainingSetSubSysP6, 1])
modelSubSysP6 = SuperLearner(Y = yTrainSubSysP6, X = xTrainSubSusP6, family = binomial(), SL.library = algorithmList)
predictionSubSysP1 = predict.SuperLearner(modelSubSysP6, newdata = xTestSubSysP6)
predictedResultSubSysP6 = as.numeric(ifelse(predictionSubSysP6$pred>=0.5,1,0))
confMatrixSubSysP6 = confusionMatrix(as.factor(yTestSubSysP6), as.factor(predictedResultSubSysP6))
# SybSystemP5 modeling
modelSubSysP5 = SuperLearner(Y = yTrainSubSysP5, X = xTrainSubSusP5, family = binomial(), SL.library = algorithmList)
predictionSubSysP5 = predict.SuperLearner(modelSubSysP5, newdata = xTestSubSysP5)
predictedResultSubSysP5 = as.numeric(ifelse(predictionSubSysP5$pred>=0.5,1,0))
confMatrixSubSysP5 = confusionMatrix(as.factor(yTestSubSysP5), as.factor(predictedResultSubSysP5))
listWrappers()
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(xgboost)
listWrappers()
data = hw8_data
options(mc.cores = 7)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# Reduce to a dataset random observations.
trainingSet = sample(seq_len(nrow(data)), size = floor(0.66*nrow(data)))
xTrain = data[trainingSet,2:38]
xTest = data[-trainingSet,2:38]
yTrain = as.numeric(data[trainingSet, 1])
yTest = as.numeric(data[-trainingSet, 1])
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost","SL.svm","SL.lm")
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
source('~/Documents/theDataMiningProject/Part 2/superlerner.R')
hw8_data <- read.csv("~/Documents/theDataMiningProject/Part 2/hw8_data.csv")
View(hw8_data)
source('~/Documents/theDataMiningProject/Part 2/superlerner.R')
source('~/Documents/theDataMiningProject/Part 2/superlerner.R')
confMatrix
summary(cv_sl)
source('~/Documents/theDataMiningProject/Part 2/subsystemSuperLearner.R')
confMatrixSubSysP3
# SubSystemP3 CrossFold Validation for calculating Area Under Curve
system.time({
cv_slSubSysP3 = CV.SuperLearner(Y = yTrainSubSysP3, X = xTrainSubSusP3, family = binomial(),
# For a real analysis we would use V = 10.
V = 10,
parallel = "multicore",
method = "method.AUC",
SL.library = algorithmList)
})
summary(cv_slSubSysP3)
rec <- hc(hw8_data)
load(bnlearn)
load(bnlearn)
install.packages("bnlearn")
library(bnlearn)
rec <- hc(hw8_data)
load("~/Documents/theDataMiningProject/Part 2/weka/informationgainAndChangeIsAttackToNominal.R")
data = hw8_data
data$is_attact<-ifelse(data$is_attact==0,'no','yes')
data = hw8_data
data$is_attact<-ifelse(data$is_attact==0,'no','yes')
data$is_attack<-ifelse(data$is_attack==0,'no','yes')
View(data)
rec <- hc(data)
confMatrix
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
prediction = predict.SuperLearner(model, newdata = xTest)
predictedResult = as.numeric(ifelse(prediction$pred>=0.5,1,0))
confMatrix = confusionMatrix(as.factor(yTest), as.factor(predictedResult))
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(xgboost)
data = hw8_data
options(mc.cores = 7)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
prediction = predict.SuperLearner(model, newdata = xTest)
predictedResult = as.numeric(ifelse(prediction$pred>=0.5,1,0))
confMatrix = confusionMatrix(as.factor(yTest), as.factor(predictedResult))
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(xgboost)
# listWrappers()
#load data into frame
data = hw8_data
options(mc.cores = 7)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# Reduce to a dataset random observations.
trainingSet = sample(seq_len(nrow(data)), size = floor(0.66*nrow(data)))
xTrain = data[trainingSet,2:38]
xTest = data[-trainingSet,2:38]
yTrain = as.numeric(data[trainingSet, 1])
yTest = as.numeric(data[-trainingSet, 1])
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
system.time({
crossFoldValidation = CV.SuperLearner(yTrain, xTrain, V = 10, parallel = "multicore", family = binomial(), SL.library = algorithmList)
})
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
prediction = predict.SuperLearner(model, newdata = xTest)
predictedResult = as.numeric(ifelse(prediction$pred>=0.5,1,0))
confMatrix = confusionMatrix(as.factor(yTest), as.factor(predictedResult))
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
prediction = predict.SuperLearner(model, newdata = xTest)
predictedResult = as.numeric(ifelse(prediction$pred>=0.5,1,0))
confMatrix = confusionMatrix(as.factor(yTest), as.factor(predictedResult))
confMatrix
source('~/Documents/theDataMiningProject/Part 2/superlerner.R')
install.packages("c50")
install.packages("C50")
hw8_data <- read.csv("~/Documents/theDataMiningProject/Part 2/updateDataset.csv")
View(hw8_data)
load("~/Documents/theDataMiningProject/Part 2/superlerner.R")
load("~/Documents/theDataMiningProject/Part 2/superlerner.R")
setwd("~/Documents/theDataMiningProject/Part 2")
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(xgboost)
# listWrappers()
#load data into frame
data = hw8_data
options(mc.cores = 7)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# Reduce to a dataset random observations.
trainingSet = sample(seq_len(nrow(data)), size = floor(0.66*nrow(data)))
xTrain = data[trainingSet,2:38]
xTest = data[-trainingSet,2:38]
yTrain = as.numeric(data[trainingSet, 1])
yTest = as.numeric(data[-trainingSet, 1])
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
options(mc.cores = 2)
library(C50)
C5.0(xTrain, yTrain)
C5.0(data[1:38, -1], data[1:38, 1])
c50Model = C5.0(data[1:38, -1], data[1:38, 1])
View(data)
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(xgboost)
# listWrappers()
#load data into frame
data = hw8_data
options(mc.cores = 2)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# Reduce to a dataset random observations.
trainingSet = sample(seq_len(nrow(data)), size = floor(0.66*nrow(data)))
xTrain = data[trainingSet,2:38]
xTest = data[-trainingSet,2:38]
yTrain = as.numeric(data[trainingSet, 1])
yTest = as.numeric(data[-trainingSet, 1])
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(xgboost)
# listWrappers()
#load data into frame
data = hw8_data
options(mc.cores = 2)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# Reduce to a dataset random observations.
trainingSet = sample(seq_len(nrow(data)), size = floor(0.66*nrow(data)))
xTrain = data[trainingSet,2:38]
xTest = data[-trainingSet,2:38]
yTrain = as.numeric(data[trainingSet, 1])
yTest = as.numeric(data[-trainingSet, 1])
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
system.time({
crossFoldValidation = CV.SuperLearner(yTrain, xTrain, V = 10, parallel = "multicore", family = binomial(), SL.library = algorithmList)
})
options(mc.cores = 4)
system.time({
crossFoldValidation = CV.SuperLearner(yTrain, xTrain, V = 10, parallel = "multicore", family = binomial(), SL.library = algorithmList)
})
crossFoldValidation
crossFoldValidation$library.predict
crossFoldValidation$SL.predict
crossFoldValidation$SL.library
plot(crossFoldValidation)
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
prediction = predict.SuperLearner(model, newdata = xTest)
predictedResult = as.numeric(ifelse(prediction$pred>=0.5,1,0))
confMatrix = confusionMatrix(as.factor(yTest), as.factor(predictedResult))
confMatrix
system.time({
cv_sl = CV.SuperLearner(Y = yTrain, X = xTrain, family = binomial(),
# For a real analysis we would use V = 10.
V = 10,
parallel = "multicore",
method = "method.AUC",
SL.library = algorithmList)
})
summary(cv_sl)
plot(cv_sl)
hw8_data <- read.csv("~/Documents/theDataMiningProject/Part 2/hw8_data.csv")
View(hw8_data)
hw8_data <- read.csv("~/Documents/theDataMiningProject/Part 2/hw8_data.csv")
View(hw8_data)
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(parallel)
library(xgboost)
library(ranger)
# listWrappers()
#load data into frame
data = hw8_data
options(mc.cores = 4)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# Reduce to a dataset random observations.
trainingSet = sample(seq_len(nrow(data)), size = floor(0.66*nrow(data)))
xTrain = data[trainingSet,2:38]
xTest = data[-trainingSet,2:38]
yTrain = as.numeric(data[trainingSet, 1])
yTest = as.numeric(data[-trainingSet, 1])
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
system.time({
crossFoldValidation = CV.SuperLearner(yTrain, xTrain, V = 10, parallel = "multicore", family = binomial(), SL.library = algorithmList)
})
plot(crossFoldValidation)
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
prediction = predict.SuperLearner(model, newdata = xTest)
predictedResult = as.numeric(ifelse(prediction$pred>=0.5,1,0))
confMatrix = confusionMatrix(as.factor(yTest), as.factor(predictedResult))
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(parallel)
library(xgboost)
library(ranger)
# listWrappers()
#load data into frame
data = hw8_data
options(mc.cores = 4)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# Reduce to a dataset random observations.
trainingSet = sample(seq_len(nrow(data)), size = floor(0.66*nrow(data)))
xTrain = data[trainingSet,2:38]
xTest = data[-trainingSet,2:38]
yTrain = as.numeric(data[trainingSet, 1])
yTest = as.numeric(data[-trainingSet, 1])
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
source('~/Documents/theDataMiningProject/Part 2/superlerner.R')
hw8_data <- read.csv("~/Documents/theDataMiningProject/Part 2/hw8_data.csv")
View(hw8_data)
library(SuperLearner)
library(KernelKnn)
library(kernlab)
library(dplyr)
library(caret)
library(e1071)
library(bnlearn)
library(arules)
library(arm)
library(parallel)
library(xgboost)
library(ranger)
# listWrappers()
#load data into frame
data = hw8_data
options(mc.cores = 4)
getOption("mc.cores")
set.seed(1, "L'Ecuyer-CMRG")
# Reduce to a dataset random observations.
trainingSet = sample(seq_len(nrow(data)), size = floor(0.66*nrow(data)))
xTrain = data[trainingSet,2:38]
xTest = data[-trainingSet,2:38]
yTrain = as.numeric(data[trainingSet, 1])
yTest = as.numeric(data[-trainingSet, 1])
SL.kernelKnnManhattan = function(...) {
SL.kernelKnn(..., method = "manhattan", k=5)
}
algorithmList = list("SL.mean","SL.ranger","SL.ksvm","SL.kernelKnnManhattan","SL.bayesglm","SL.xgboost")
model = SuperLearner(Y = yTrain, X = xTrain, family = binomial(), SL.library = algorithmList)
prediction = predict.SuperLearner(model, newdata = xTest)
predictedResult = as.numeric(ifelse(prediction$pred>=0.5,1,0))
confMatrix = confusionMatrix(as.factor(yTest), as.factor(predictedResult))
plot(model)
confMatrix
system.time({
cv_sl = CV.SuperLearner(Y = yTrain, X = xTrain, family = binomial(),
# For a real analysis we would use V = 10.
V = 10,
parallel = "multicore",
method = "method.AUC",
SL.library = algorithmList)
})
plot(cv_sl)
summary(cv_sl)
View(hw8_data)
